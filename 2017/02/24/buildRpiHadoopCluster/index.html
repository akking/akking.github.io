<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Building a Hadoop cluser using Raspberry Pi | Dongyan Li&#39;s Notebook</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Why build this cluster?Good part:
Raspberry Pi runs the same Linux and Hadoop as Amazon EC2 does. Good for learning and testing.
Cheap, less than $200 for the whole system. 40w power consumption, alwa">
<meta property="og:type" content="article">
<meta property="og:title" content="Building a Hadoop cluser using Raspberry Pi">
<meta property="og:url" content="http://yoursite.com/2017/02/24/buildRpiHadoopCluster/index.html">
<meta property="og:site_name" content="Dongyan Li's Notebook">
<meta property="og:description" content="Why build this cluster?Good part:
Raspberry Pi runs the same Linux and Hadoop as Amazon EC2 does. Good for learning and testing.
Cheap, less than $200 for the whole system. 40w power consumption, alwa">
<meta property="og:image" content="http://yoursite.com/images/assembledCluster.png">
<meta property="og:image" content="http://yoursite.com/images/yarn.png">
<meta property="og:image" content="http://yoursite.com/images/2.png">
<meta property="og:updated_time" content="2017-02-24T18:15:52.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Building a Hadoop cluser using Raspberry Pi">
<meta name="twitter:description" content="Why build this cluster?Good part:
Raspberry Pi runs the same Linux and Hadoop as Amazon EC2 does. Good for learning and testing.
Cheap, less than $200 for the whole system. 40w power consumption, alwa">
<meta name="twitter:image" content="http://yoursite.com/images/assembledCluster.png">
  
    <link rel="alternate" href="/atom.xml" title="Dongyan Li&#39;s Notebook" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Dongyan Li&#39;s Notebook</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-buildRpiHadoopCluster" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/02/24/buildRpiHadoopCluster/" class="article-date">
  <time datetime="2017-02-24T18:01:56.000Z" itemprop="datePublished">2017-02-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Building a Hadoop cluser using Raspberry Pi
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h1 id="Why-build-this-cluster"><a href="#Why-build-this-cluster" class="headerlink" title="Why build this cluster?"></a>Why build this cluster?</h1><h2 id="Good-part"><a href="#Good-part" class="headerlink" title="Good part:"></a>Good part:</h2><ul>
<li>Raspberry Pi runs the same Linux and Hadoop as Amazon EC2 does. Good for learning and testing.</li>
<li>Cheap, less than $200 for the whole system. 40w power consumption, always on 24x7.</li>
<li>Under same network, no server down, command response has zero lag.</li>
<li>Versatile, could be multi-machine web server or own cloud.</li>
<li>Sits on the desk, actually own the server, feels good.</li>
</ul>
<h2 id="But"><a href="#But" class="headerlink" title="But:"></a>But:</h2><ul>
<li>ARM architecture at low clock speed, slow. Not suited for any big-size dataset.</li>
<li>However, you can test a little portion of large datasets before shipping to the AWS.</li>
</ul>
<h1 id="Cluster-Physical-Setup"><a href="#Cluster-Physical-Setup" class="headerlink" title="Cluster Physical Setup"></a>Cluster Physical Setup</h1><h2 id="Cluster-Specs"><a href="#Cluster-Specs" class="headerlink" title="Cluster Specs"></a>Cluster Specs</h2><ul>
<li>4 x Raspberry Pi 3 with 64 GB SD card</li>
<li>Gigabit Ethernet Switch for Inter-Nodes talk</li>
<li>Cables and Power</li>
</ul>
<h2 id="Assembly"><a href="#Assembly" class="headerlink" title="Assembly"></a>Assembly</h2><ul>
<li>In order to “stack” the parts together, I ordered a stacking kit which can be stacked together with Raspberry Pi. </li>
<li>For power supply, I used a 40W 5-Port USB charger with a max output of 2.4A for each port.<br>Official recommend using a 2.5Amp power supply for each of the Raspberry Pi 3 but I highly doubt they can use that much power. </li>
<li>Since Raspberry Pi 3 has a build-in WIFI adapter, it’s not necessary to use any wired connections in order<br>to let cluster work. However, for the sake of stability and adaptability, I used a Gigabit Ethernet Switch for inter-nodes communication.<br>Whenever you need to bring the cluster to somewhere else, you only need to connect the master node to the Internet by wire or WIFI.</li>
<li>The picture of fully assembled cluster: (in the next page due to PDF output)</li>
</ul>
<p><img src="/images/assembledCluster.png" alt="assembled cluster"></p>
<h1 id="Cluster-Software-Setup"><a href="#Cluster-Software-Setup" class="headerlink" title="Cluster Software Setup"></a>Cluster Software Setup</h1><h2 id="Install-Linux-Image"><a href="#Install-Linux-Image" class="headerlink" title="Install Linux Image"></a>Install Linux Image</h2><p>For Linux distribution, I used <a href="https://www.raspberrypi.org/downloads/raspbian/" target="_blank" rel="external">RASPBIAN</a> which is official supported operating system. I used <code>RASPBIAN JESSIE LITE</code> which contains no GUI and has only <code>292 MB</code>. </p>
<p>In order to avoid some <em>stupid mistaks</em> which need several hours to find out, I install the Linux System and Hadoop only into <strong>one</strong> machine,<br>configure and test the Hadoop to check if everything is OK and then<br>dump the whole SD card image to other three of them.</p>
<p>Installation:</p>
<ol>
<li>Insert the SD card to my MacBook</li>
<li><code>diskutil list</code> to list the mounted driver</li>
<li><p>unmount the SD card for writing the image:</p>
<p>   diskutil unmountDisk /dev/disk<disk# from="" diskutil=""></disk#></p>
<p>in my case is <code>disk3</code></p>
</li>
<li><p>write the image to SD card: </p>
<p>   sudo dd bs=1m if=image.img of=/dev/rdisk<disk# from="" diskutil=""></disk#></p>
<p>and in my case:</p>
<pre><code>sudo dd bs=1m if=/Users/DLI/Downloads/2016-05-27-raspbian-jessie-lite.img of=/dev/rdisk3`
</code></pre></li>
</ol>
<h2 id="OS-setup-and-Hadoop-Compilation"><a href="#OS-setup-and-Hadoop-Compilation" class="headerlink" title="OS setup and Hadoop Compilation"></a>OS setup and Hadoop Compilation</h2><h3 id="Connect-to-RPi"><a href="#Connect-to-RPi" class="headerlink" title="Connect to RPi:"></a>Connect to RPi:</h3><ul>
<li>Insert SD card into one the RPi and connect that RPi to my home router. For clarity, I will name this RPi <strong>masterPi</strong>.</li>
<li>Then, log into my router to find the IP address of <strong>masterPi</strong>,<br>which is <code>192.168.1.125</code>. Then, manually assign an IP address to masterPi<br>so I don’t need to check the address of that masterPi after rebooting.</li>
<li><p>log into the <code>masterPi</code>:</p>
<p>  SSH pi@192.168.1.125</p>
<p>with a pre-set password: <code>raspberry</code></p>
</li>
<li><p>expand the file system and configure the locale setting with <code>sudo raspi-config</code></p>
</li>
<li><p>do a</p>
<p>  sudo apt-get update &amp;&amp; sudo apt-get upgrade</p>
<p>to keep the system fresh</p>
</li>
<li><p>add a new user <code>HadoopUser</code> into a <strong>sudo</strong> group <code>hadoop</code>:</p>
<pre><code>sudo addgroup hadoop
sudo adduser --ingroup hadoop HadoopUser
</code></pre><p>shell give me a warning: <code>adduser: Please enter a username matching the regular expression configured</code><br>after some research it seems that Linux doesn’t recommend mixing upper and lower case name,<br>so I used </p>
<pre><code>sudo adduser --ingroup hadoop hadoopuser
</code></pre><p>instead (Lession learnt…), then add <code>hadoopuser to sudo group</code></p>
<pre><code>sudo adduser hadoopuser sudo
</code></pre></li>
</ul>
<h3 id="Install-JDK"><a href="#Install-JDK" class="headerlink" title="Install JDK"></a>Install JDK</h3><ul>
<li>it is reported that the Oracle JDK has better performance over <code>Open JDK</code>, so: <code>sudo apt-get install oracle-java8-jdk</code><br>note: JDK is installed on <code>/usr/lib/jvm/</code></li>
<li><p>check if</p>
<p>  java -version</p>
<p>points to Oracle JDK</p>
</li>
</ul>
<h3 id="Download-source-code"><a href="#Download-source-code" class="headerlink" title="Download source code"></a>Download source code</h3><p>From <a href="http://www-us.apache.org/dist/hadoop/common/hadoop-2.7.2/hadoop-2.7.2-src.tar.gz" target="_blank" rel="external"><code>hadoop-2.7.2</code></a></p>
<h3 id="Compile"><a href="#Compile" class="headerlink" title="Compile"></a>Compile</h3><p>A quick look at the <a href="https://svn.apache.org/repos/asf/hadoop/common/branches/MR-4327/BUILDING.txt" target="_blank" rel="external"><code>Building Instruction</code></a> of Hadoop from Apache, Hadoop has the following requirements:</p>
<ul>
<li>Unix System</li>
<li>JDK 1.6</li>
<li>Maven 3.0</li>
<li>Forrest 0.8 (if generating docs)</li>
<li>Findbugs 1.3.9 (if running findbugs)</li>
<li>ProtocolBuffer 2.4.1+ (for MapReduce and HDFS)</li>
<li>CMake 2.6 or newer (if compiling native code)</li>
<li>Internet connection for first build (to fetch all Maven and Hadoop dependencies)</li>
</ul>
<p>Addition to JDK, I need at least Maven,ProtocolBuffer and CMake so install them accordingly:</p>
<ul>
<li><code>apt-get install maven</code>, a lot of dependencies but <code>apt-get</code> covered me nicely :)</li>
<li>installing ProtocolBuffer is a little tricky</li>
<li>we must download the <a href="https://github.com/google/protobuf/blob/master/src/README.md" target="_blank" rel="external">source</a>, then <code>./autogen.sh</code>, as specified in the offical site</li>
<li><p>by default, ProtocolBuffer install the file to <code>/usr/local</code> which may not be found by the system, so reconfig it to <code>/usr</code>:</p>
<pre><code>./configure --prefix=/usr
</code></pre><p>and then </p>
<pre><code>make
</code></pre></li>
<li><p><code>make check</code> to check if builds OK and returns:</p>
<pre><code>=====================================================
Testsuite summary for Protocol Buffers 3.0.0-beta-3
=====================================================
# TOTAL: 6
# PASS:  6
# SKIP:  0
# XFAIL: 0
# FAIL:  0
# XPASS: 0
# ERROR: 0
=====================================================
</code></pre></li>
<li><p>download the <a href="http://www-us.apache.org/dist/hadoop/common/hadoop-2.7.2/hadoop-2.7.2-src.tar.gz" target="_blank" rel="external"><code>hadoop-2.7.2</code></a> source code unzip with</p>
<p>  tar xzvf hadoop-2.7.2-src.tar.gz</p>
</li>
<li><p>compile the Hadoop natively for RPi</p>
<p>  cd hadoop-2.7.2-src/<br>  sudo mvn package -Pdist,native -DskipTests -Dtar</p>
</li>
<li><p>However, I get the error message in the mid of compiling process:</p>
<blockquote>
<p>[ERROR] Failed to execute goal org.apache.hadoop:hadoop-maven-plugins:2.7.2:protoc (compile-protoc) on project hadoop-common: org.apache.maven.plugin.MojoExecutionException: ‘protoc –version’ did not return a version -&gt; [Help 1].</p>
</blockquote>
<p>  After some search online, building Hadoop need version of <code>protocol buffers</code> exactly be <code>2.5</code>. So I need to delete the one I installed and rebuild Hadoop.</p>
</li>
<li>Another 45 minutes of life, I finally get <code>protocol buffers version 2.5</code> compiled.</li>
<li><p>Again: </p>
<p>  sudo mvn package -Pdist,native -DskipTests -Dtar</p>
</li>
<li><p>Finally:</p>
<p>  [INFO] ————————————————————————<br>  [INFO] BUILD SUCCESS<br>  [INFO] ————————————————————————<br>  [INFO] Total time: 53:22.700s<br>  [INFO] Finished at: Thu Jun 09 23:08:57 CDT 2016<br>  [INFO] Final Memory: 81M/224M<br>  [INFO] ————————————————————————</p>
</li>
</ul>
<p>Test the build:</p>
<pre><code>bin/hadoop checknative -a
</code></pre><p>And the output: </p>
<pre><code>Native library checking:
hadoop:  true /home/hadoopuser/hadoop-2.7.2-src/hadoop-dist/target/hadoop-2.7.2/lib/native/libhadoop.so.1.0.0
zlib:    true /lib/arm-linux-gnueabihf/libz.so.1
snappy:  true /usr/lib/libsnappy.so.1
lz4:     true revision:99
bzip2:   true /lib/arm-linux-gnueabihf/libbz2.so.1
openssl: true /usr/lib/arm-linux-gnueabihf/libcrypto.so
</code></pre><p>Test with</p>
<pre><code>$ bin/hdfs dfs -put etc/hadoop input
$ bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar grep input output &apos;dfs[a-z.]+&apos;
</code></pre><p>View the output with</p>
<pre><code>$ bin/hdfs dfs -cat output/*
</code></pre><p>Output:</p>
<pre><code>6       dfs.audit.logger
4       dfs.class
3       dfs.server.namenode.
2       dfs.period
2       dfs.audit.log.maxfilesize
2       dfs.audit.log.maxbackupindex
1       dfsmetrics.log
1       dfsadmin
1       dfs.servers
1       dfs.replication
1       dfs.file
</code></pre><p>Everything seems OK, moving to next step:</p>
<h2 id="Clone-image-to-other-RPi"><a href="#Clone-image-to-other-RPi" class="headerlink" title="Clone image to other RPi"></a>Clone image to other RPi</h2><p>Insert the SD card from Pi to my laptop, and then</p>
<pre><code>$ sudo dd if=/dev/sdb of=node1.img
$ sudo dd if=node1.img of=/dev/sdb
</code></pre><p>Do it 3 times to clone the image to other three slave nodes.</p>
<h1 id="Pseudo-distributed-mode-test"><a href="#Pseudo-distributed-mode-test" class="headerlink" title="Pseudo-distributed mode test"></a>Pseudo-distributed mode test</h1><h2 id="Setup"><a href="#Setup" class="headerlink" title="Setup"></a>Setup</h2><p>In <code>core-site.xml</code></p>
<pre><code>configuration&gt;
    &lt;property&gt;
        &lt;name&gt;fs.defaultFS&lt;/name&gt;
        &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre><p>And for <code>etc/hadoop/hdfs-site.xml</code>:</p>
<pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.replication&lt;/name&gt;
        &lt;value&gt;1&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre><p>Then, formate the namenode:</p>
<pre><code>$ bin/hdfs namenode -format
</code></pre><p>Start the DataNode:</p>
<pre><code>$ sbin/start-dfs.sh
</code></pre><p>And <code>jps</code> shows:</p>
<pre><code>2608 DataNode
2774 SecondaryNameNode
2520 NameNode
2968 Jps
</code></pre><h2 id="wordcount-test"><a href="#wordcount-test" class="headerlink" title="wordcount test"></a>wordcount test</h2><p>Download the <code>bioproject.xml</code> from HW1:</p>
<pre><code>wget http://rasinsrv07.cstcis.cti.depaul.edu/CSC555/bioproject.xml
</code></pre><p>put into HDFS:</p>
<pre><code>$ bin/hdfs dfs -put bioproject.xml bioproject
</code></pre><p>run wordcount:<br>​<br>    root@masterPi:~/hadoop-2.7.2# time bin/hadoop jar<br>    .. share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar<br>    .. wordcount bioproject bioprojectOutput2</p>
<p>time report:</p>
<pre><code>real    8m39.367s
user    8m51.510s
sys     0m15.360s
</code></pre><p>not bad compared to Amazon EC2’s single-node cluster with 1m30s.</p>
<h1 id="Two-Three-Four-nodes-comparison"><a href="#Two-Three-Four-nodes-comparison" class="headerlink" title="Two, Three, Four nodes comparison"></a>Two, Three, Four nodes comparison</h1><h2 id="two-node-cluster"><a href="#two-node-cluster" class="headerlink" title="two-node cluster"></a>two-node cluster</h2><h3 id="setup"><a href="#setup" class="headerlink" title="setup"></a>setup</h3><p>hdfs-site.xml: I lower the block size because of the test sample file size</p>
<pre><code>&lt;configuration&gt;
    &lt;property&gt;
    &lt;name&gt;dfs.replication&lt;/name&gt;
    &lt;value&gt;2&lt;/value&gt;
&lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.blocksize&lt;/name&gt;
        &lt;value&gt;32m&lt;/value&gt;
        &lt;description&gt;Block size&lt;/description&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre><p>and yarn-site.xml:<br>​<br>    <configuration><br>    <property><br>          <name>yarn.resourcemanager.resource-tracker.address</name><br>          <value>master:8025</value><br>    </property><br>    <property><br>          <name>yarn.resourcemanager.scheduler.address</name><br>          <value>master:8030</value><br>    <property><br>    </property><br>          <name>yarn.resourcemanager.address</name><br>          <value>master:8050</value><br>    </property><br>    </configuration></p>
<p>then:</p>
<pre><code>bin/hdfs namenode -format
</code></pre><p>and:</p>
<pre><code>sbin/start-all.sh
</code></pre><p> Check on the 50070 port:</p>
<pre><code>Node    Last contact    Admin State Capacity          Used    Non DFS Used    Remaining        Blocks 
masterPi:50010 (192.168.3.1:50010)  1   In Service  58.61 GB    222.19 MB   9.91 GB     48.48 GB    7 
slavePi1:50010 (192.168.3.2:50010)  1   In Service  58.58 GB    222.19 MB   10.44 GB    47.92 GB    7 
</code></pre><p>each of the nodes was allocated 7 blocks.<br>to start everything and try wordcount on <code>bioproject.xml</code> again.</p>
<pre><code>time bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar 
wordcount bioproject bioprojectOutput1
</code></pre><p>the result:</p>
<pre><code>real    8m55.691s
user    8m43.950s
sys     0m15.560s
</code></pre><p>is not better than the single-node cluster, why? Maybe I changed the blcok size, change it back and re-run the task: now each node has only <code>2</code> blocks<br>result:</p>
<pre><code>real    8m35.001s
user    7m73.950s
sys     0m15.560s
</code></pre><p>Still the same, why? After some careful observation of the mapreduce job, I see a lot of map -&gt; map jobs which is unrelated to the<br>mapreduce process. After searching the web, I think the problem is I’m <strong>still</strong> using the normal <code>hadoop jar ...</code> command which is not<br>replace by the <code>YARN</code> command that new to the 2.x version of Hadoop.</p>
<p><img src="/images/yarn.png" alt=""></p>
<p>After spending more time doing research on <code>YARN</code>, which is replacing the old <code>ResourceManager</code> by giving authorities to slave node for allocating containers(job runner), monitoring their resource usage.<br>I find <code>YARN</code> is a great idea since central administration is become harder and harder as the Hadoop ecosystem getting larger. With YARN and MapReduce 2, there are no longer pre-configured static slots for Map and Reduce tasks. The entire cluster is available for dynamic resource allocation of Maps and Reduces as needed by the job. So, I decided to use YARN as task manager instead of Hadoop generic mapreduce. However, after get <code>YARN</code> up and running, I keep getting:</p>
<pre><code>Container killed on request. Exit code is 137
Container exited with a non-zero exit code 137
</code></pre><p>which is the famous OOM error that the tasks is kill by the system because of not enough memory…</p>
<p>Of course I will get this error message, RPi only has 1g of RAM but YARN will allocate 1024mb of memory minimun for each container and for each node will has multiple containers for the tasks.<br>So, we must change some parameters:</p>
<p>I added the following in the yarn-set.xml:</p>
<pre><code>&lt;property&gt;
&lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt;name&gt;
&lt;value&gt;500&lt;/value&gt;
&lt;/property&gt;
</code></pre><p>Then, run with command:</p>
<pre><code>bin/yarn jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar 
wordcount /bioproject /bioprojectop1
</code></pre><p>However, I still get </p>
<pre><code>Diagnostics: Container is running beyond virtual memory limits. 
Current usage: 15.1 MB of 256 MB physical memory used; 1.1 GB of 537.6 MB virtual memory used. Killing container.
</code></pre><p>and containers were shutdown by the system,<br>Run <code>top</code> shows:</p>
<pre><code>4301 root      20   0  305860 150512   5808 S  70.2 15.1   0:24.66 java
4556 root      20   0  284684  36320  15324 S  62.6  3.6   0:04.16 java
4228 root      20   0  306728 151200   6364 S  61.0 15.2   0:28.99 java
4584 root      20   0  283660  35136  15232 S  60.6  3.5   0:03.36 java
4538 root      20   0  284684  36084  15156 S  59.0  3.6   0:04.15 java
4321 root      20   0  305704 151508   7268 S  56.7 15.2   0:21.70 java
3140 root      20   0  512012  77436   6784 S  17.5  7.8   1:09.14 java
</code></pre><p>YARN seems give too many works to a single node…</p>
<p>After another servaral hours of configuration, I can’t set parameters properly to let yarn task run successfully. I decided to move on to the next topic and leave this for later to solve.<br>remove the parameters:</p>
<pre><code>&lt;property&gt;
    &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
    &lt;value&gt;yarn&lt;/value&gt;
&lt;/property&gt;
</code></pre><p>in order to bypass the <code>YARN</code> framework and run the Mapreduce tasks directly on HDFS.</p>
<h1 id="Various-tasks-on-fully-distributed-mode"><a href="#Various-tasks-on-fully-distributed-mode" class="headerlink" title="Various tasks on fully distributed mode"></a>Various tasks on fully distributed mode</h1><p>Add other three nodes to the cluser is just add more names into the <code>slaves</code> file and everything runs smoothly.</p>
<h2 id="wordcount-on-bioproject"><a href="#wordcount-on-bioproject" class="headerlink" title="wordcount on bioproject"></a>wordcount on bioproject</h2><p>In full-cluster mode, the wordcount job on <code>bioproject</code> give us</p>
<pre><code>real    6m65.001s
user    7m33.050s
sys     0m18.560s
</code></pre><p>A about 20% decrease in time, not a big increase in performance at all. Run <code>top</code> give us some hint of reason why:</p>
<p><img src="/images/2.png" alt="s1"></p>
<p>The I/O performance of RPi is so low that CPU is idle waiting for input from the SD card. Moreover, the <code>wordcount</code> is not an CPU but IO intensive task, so the increase in cluster size doesn’t provide too much benefit for RPi.</p>
<h1 id="The-bottleneck-and-improvements"><a href="#The-bottleneck-and-improvements" class="headerlink" title="The bottleneck and improvements"></a>The bottleneck and improvements</h1><p>From the result of <code>wordcount</code> on <code>bioproject.xml</code>, we know the bottleneck is from disk IO. In order to optimize it,<br>we can lower the block size since SD card is not like traditional hardrive which has to spin the disk to read the data.</p>
<p>Also, as indicated by my unsuccessful experiment of<br>running <code>YARN</code> on top of <code>HDFS</code>, the <em>ResourceManager</em> of <code>YARN</code> could max out the CPU of RPi by spawning many (&gt;10) MapReduce containers to run the tasks in parallel, which I think<br>could potentially increase the performance. However, containers using too much RAM will get killed by the system. I need to find the sweet spot of balance of parameter setting but I didn’t succeed.</p>
<h1 id="Re-run-tasks-after-optimization"><a href="#Re-run-tasks-after-optimization" class="headerlink" title="Re-run tasks after optimization"></a>Re-run tasks after optimization</h1><p>Tweaked the blocksize to 35mb, I run the same <code>project.xml</code> again with result:</p>
<pre><code>real    6m35.833s
user    7m33.343s
sys     0m13.560s
</code></pre><p>Still, not a big improvement. Search online, I found that we could over-clock the speed of I/O in RPi by modifying the <code>/boot/config.txt</code></p>
<pre><code>sudo bash -c &apos;printf &quot;dtoverlay=sdhost,overclock_50=100\n&quot; 
&gt;&gt; /boot/config.txt&apos;
</code></pre><p>Default is 50MHz and I increased to 100. Another run of hadoop:</p>
<pre><code>real    4m52.303s
user    5m23.183s
sys     0m14.560s
</code></pre><p>Another 20%! I can still push the RPi a little more by overclocking the CPU and RAM speed but I think the increase in performance is limited.</p>
<h1 id="Final-thoughts"><a href="#Final-thoughts" class="headerlink" title="Final thoughts"></a>Final thoughts</h1><p>By moving from disk writing to scheduling of container task which could potentially max out the system resource, the new 2.x Hadoop with <code>YARN</code> architecture is one step to more <code>SPARK</code> like and I think is a elegant solution to the proliferation of Hadoop eco-system.<br>I tried to configure the <code>YARN</code> parameter correctly but after 2 days of works I still get the <code>out of memory</code> interruption in the middle of task. The reason for that is I still haven’t figured out the multiple relations of different settings. (eg: the minimum size allocated for each container should be larger than adequate but can’t exceed the memory size limit of system)</p>
<p>In conclusion, I learnt a lot from this project. I have a much better understanding of the distributed nature of Hadoop, Linux system and command line environment. Also, presenting my cluster and running demo to the classmates is a fun experience.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2017/02/24/buildRpiHadoopCluster/" data-id="cizk52x3y000calz5kac9p5n5" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2017/01/08/ReservoirSampling/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Reservoir Sampling</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/02/">February 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/01/">January 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/12/">December 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">November 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">September 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">August 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2017/02/24/buildRpiHadoopCluster/">Building a Hadoop cluser using Raspberry Pi</a>
          </li>
        
          <li>
            <a href="/2017/01/08/ReservoirSampling/">Reservoir Sampling</a>
          </li>
        
          <li>
            <a href="/2016/12/02/binary-search-and-variant/">Binary Search related topics</a>
          </li>
        
          <li>
            <a href="/2016/12/02/31-next-permutation/">31. Next Permutation</a>
          </li>
        
          <li>
            <a href="/2016/11/30/longest-substring-without-repeating-characters/">Longest Substring Without Repeating Characters</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2017 Dongyan Li<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>